{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        # Subway Data Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The NYC public transportantion system - Metro Transit Authority - provides data for download via csv files. Part of the information available are data from the subway turnstiles, containing weekly logs for cumulative entries and exits by turnstile and by subway station during a provided timeframe.\n",
    "\n",
    "\n",
    "For this project, we will only use the information available at: http://web.mta.info/developers/turnstile.html.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this project\n",
    "\n",
    "For this project, you will apply the knowledge acquired in the first month of this course. We will practice basic data acquisition and data cleaning tasks to find out fundamental stuff about the data using what we learned in the Statistics course. \n",
    "\n",
    "The goal of this project is to explore the relationship between data from the NYC Subway turnstiles and the city weather. For this, besides data from the subway, we will also need data from the weather in NYC. \n",
    "\n",
    "Here are the main points that will be considered in this work:\n",
    "\n",
    "- Gathering data from the Internet\n",
    "- Using Statistics for Data Analysis\n",
    "- Data handling and simple graphics creation with `Pandas`\n",
    "\n",
    "*How to find help*: We suggest that you try the following channels, in the following order:\n",
    "\n",
    "| Type of Question\\Channels    \t| Google \t| Forum \t| Slack \t| Email \t|\n",
    "|-------------------------------\t|--------\t|-------\t|-------\t|-------\t|\n",
    "| Pandas and Python Programming \t| 1      \t| 2     \t| 3     \t|       \t|\n",
    "| Projects Requiriments         \t|        \t| 1     \t| 2     \t| 3     \t|\n",
    "| Projects Specific Parts       \t|        \t| 1     \t| 2     \t| 3     \t|\n",
    "\n",
    "Here is the address for each of these channels:\n",
    "\n",
    "- Forum: https://discussions.udacity.com/c/ndfdsi-project\n",
    "- Slack: [Big Data Foundations](https://goo.gl/4K7LWK)\n",
    "- Email: india@udacity.com\n",
    "\n",
    "**The student is expected to submit this report including:**\n",
    "\n",
    "- All TODO's completed, as they are crucial for the code to run accordingly\n",
    "- The ipynb file, exported as html\n",
    "\n",
    "To submit this project, go to the [classroom](https://coco.udacity.com/nanodegrees/nd100-inbig/locale/en-us/versions/1.0.0/parts/469348/modules/469702/lessons/469703/project), and submit your zipped `.ipynb` and html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminders\n",
    "\n",
    "Before we start, there are a few things you must have in mind while using iPython notebooks:\n",
    "\n",
    "- Remember you can see, in the left side of a code cell, when was the last time it ran, if there is a number inside the keys.\n",
    "- When starting a new session in the notebook, please make sure to run all cells up to the point where you last left it. Even if the output can still be viewed from the moment you ran your cells in the previews session, the kernel starts in a new state, so you will need to reload all data, etc. in a new session.\n",
    "- The previous point is useful to have in mind if your answers do not match what is expected from the quizzes in the classroom. Try reloading the data and running all processing steps, one by one, to make sure you're working with the same variables and data from each step of the quizz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note-: Before Starting this project please go through all the instructions stated in README.md file.\n",
    "\n",
    "## Session 1 - Data Gathering\n",
    "\n",
    "### *Exercise 1.1*\n",
    "\n",
    "Let's do it!! Now it's your turn to gather data. Please write bellow a Python code to access the link http://web.mta.info/developers/turnstile.html and download all files from June 2017. The file must be named turnstile_100617.txt, where 10/06/17 is the file's date.\n",
    "\n",
    "Please see below a few commands that might help you:\n",
    "\n",
    "Use the **urllib** library to open and redeem a webpage. Use the command below, where **url** is the webpage path to the following file:\n",
    "\n",
    "```python\n",
    "u = urllib.urlopen(url)\n",
    "html = u.read()\n",
    "```\n",
    "\n",
    "Use the **BeautifulSoup** library to search for the link to the file you want to donwload in the page. Use the command below to create your *soup* object and search for all 'a' tags in the document:\n",
    " \n",
    " \n",
    "```python\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.find_all('a')\n",
    "```\n",
    "\n",
    "A tip to only download the files from June is to check data in the name of the file. For instance, to donwload the 17/06/2017 file, please see if the link ends with *\"turnstile_170610.txt\"*. If you forget to do this, you will download all files from that page. In order to do this, you can use the following command:\n",
    "\n",
    "```python\n",
    "if '1706' in link.get('href'):\n",
    "```\n",
    "\n",
    "Our final tip is to use the command bellow to download the txt file:\n",
    "\n",
    "```python\n",
    "urllib.urlretrieve(link_do_arquivo, filename)\n",
    "```\n",
    "\n",
    "Please remember - you first have to load all packages and functions that will be used in your analysys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the necessary modules needed are imported over here\n",
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#your code here\n",
    "url =  'http://web.mta.info/developers/turnstile.html' #This is the url from where file is downloaded\n",
    "u = urllib.request.urlopen(url)\n",
    "html = u.read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.find_all('a')\n",
    "for x in links:\n",
    "    reference=x.get('href') #It is used to fetch the href part of the <a> tag.\n",
    "    if reference is not None and '1706' in reference:\n",
    "        filename = \"turnstile_\" + reference[-6:-4] + reference[-8:-6] + reference[-10:-8]+\".txt\" #It is used to slice the string from the end and changed the file format from yyyy/mm/dd to dd/mm/yyyy. The End is indexed -1 and the result produced at the end is a file named turnstile_030617.txt to turnstile_240617.txt   \n",
    "        url_fetch = 'http://web.mta.info/developers/'+ reference #The necessary file is downloaded from this url.\n",
    "        urllib.request.urlretrieve(url_fetch,filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.2*\n",
    "\n",
    "Write down a function that takes the list of all names of the files you downloaded in Exercise 1.1 and compile them into one single file. There must be only one header line in the output file. \n",
    "\n",
    "For example, if file_1 has:\n",
    "line 1...\n",
    "line 2...\n",
    "\n",
    "and the other file, file_2, has:\n",
    "line 3...\n",
    "line 4...\n",
    "line 5...\n",
    "\n",
    "We must combine file_1 and file_2 into one master file, as follows:\n",
    "\n",
    "'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "line 1...\n",
    "line 2...\n",
    "line 3...\n",
    "line 4...\n",
    "line 5...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is list of the important files needed and all of these files must be present in one folder.\n",
    "filenames = {\"turnstile_030617.txt\",\"turnstile_100617.txt\",\"turnstile_170617.txt\",\"turnstile_240617.txt\"}\n",
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,STATION, LINENAME, DIVISION, DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in sorted(filenames):#Now this is used to display the files in the sorted order that is(The content of the file1 is displayed first, then second and at the last third file. )\n",
    "            with open(filename,'r') as current_file: #used to open the current file from the list of files.\n",
    "                next(current_file) #It is used to skip the header part of the current file.\n",
    "                master_file.write(current_file.read()) #This is used to read the whole current file's characters as a string and write it to the main master file.\n",
    "    return None\n",
    "\n",
    "create_master_turnstile_file(filenames,'Output_File.txt') #This is the name of the resultant file which contains the comipiled data of all the files stated above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.3*\n",
    "\n",
    "For this exercise, you will write a function that reads the master_file created in the previous exercise and load it into a Pandas Dataframe. This function can be filtered, so that the Dataframe only has lines where column \"DESCn\" has the value \"Regular\".\n",
    "\n",
    "For example, if the Pandas Dataframe looks like this:\n",
    "    \n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "\n",
    "The Dataframe must look like the following, after filtering only the lines where column DESCn has the value REGULAR:\n",
    "\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an important module which is used to read the data from the file.\n",
    "import pandas as ps\n",
    "\n",
    "Input_File=open(\"Output_File.txt\",'r')#This is output file which we created in the earlier exercise 1.3 and is used as an input file over here.\n",
    "\n",
    "def filter_by_regular(filename):#This is the defined function.\n",
    "    \n",
    "    turnstile_data = ps.read_csv(\"Output_File.txt\")#Using the module pandas we are reading the data of the file 'Output_File.txt' over here.\n",
    "    turnstile_data = turnstile_data.loc[turnstile_data['DESCn']=='REGULAR']#turnstile_data.loc is used to directly access the locations as per the requirement. For example in this case it will select the rows having 'REGULAR' as value of 'DESCn' column.\n",
    "    return turnstile_data\n",
    "\n",
    "df=filter_by_regular(Input_File)\n",
    "df.to_csv(\"Output_File.txt\",index=None)#This is already existing output file in the folder and is updated to produce the desired results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exercise 1.4\n",
    "The NYC Subway data has cumulative entry and exit data in each line. Let's assume you have a Dataframe called df, which contains only lines for one particular turnstile (unique SCP, C/A, and UNIT). The following function must change these cumulative entries for counting all entries since the last reading (entries from the last line of the Dataframe).\n",
    "\n",
    "More specifically, there are two things you should do:\n",
    "\n",
    "1 - Create a new column, called ENTRIESn_hourly 2 - Insert in this column the difference between ENTRIESn in the current and the previous column. If the line has any NAN, fill it out/replace by 1.\n",
    "\n",
    "Tip: The funtions shift() and fillna() in Pandas might be usefull for this exercise.\n",
    "\n",
    "Below you will find and example of how your Dataframe should look by the end of this exercise:\n",
    "\n",
    "    C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is to used to read the data from the file.\n",
    "import pandas as ps\n",
    "\n",
    "input_frame = ps.read_csv(\"Output_File.txt\")#This is our file created in ealier exercise 1.3 through which we read our data.\n",
    "\n",
    "def get_hourly_entries(data_file):\n",
    "    data_file['ENTRIESn_hourly']=data_file['ENTRIESn']-data_file['ENTRIESn'].shift(1)#This is used to create a new column 'ENTRIESn_hourly' which is assigned the difference of the values of i and i-1 row of the \"ENTRIESn\" column. data_file.shift(x) is used to shift by x units. \n",
    "    data_file.fillna(value=1,inplace=True)#fills NAN value with x\n",
    "    data_file.ENTRIESn_hourly = data_file.ENTRIESn_hourly.astype(int) #This is used to convert the datatype of the 'ENTRIESn_hourly' column from float to int.\n",
    "    \n",
    "    return data_file\n",
    "\n",
    "output_frame = get_hourly_entries(input_frame)\n",
    "output_frame.to_csv(\"Output_File.txt\",index=None)#This is our output file containing the deired results which will be used in the next exercise and without wirting index=None an extra column will added displaying the index values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.5*\n",
    "\n",
    "Do the same thing you did in the previous exercise, but taking into account the exits, column EXITSn.\n",
    "For this, you need to create a column called EXITSn_hourly and insert the difference between the column EXITSn in the current line vs he previous line. If there is any NaN, fill it out/replace by 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is used to read the data from the input file.\n",
    "import pandas as ps\n",
    "\n",
    "input_frame = ps.read_csv(\"Output_File.txt\")#This is our file created in ealier exercise 1.4 through which we read our data.\n",
    "\n",
    "def get_hourly_exits(data_file):\n",
    "    data_file['EXITSn_hourly']=data_file['EXITSn']-data_file['EXITSn'].shift(1)#This is used to create a new column 'ENTRIESn_hourly' which is assigned the difference of the values of i and i-1 row of the \"ENTRIESn\" column. data_file.shift(x) is used to shift by x units.\n",
    "    data_file.fillna(value=0,inplace=True)#fills NAN value with x\n",
    "    data_file.EXITSn_hourly = data_file.EXITSn_hourly.astype(int) #This is used to convert the datatype of the 'ENTRIESn_hourly' column from float to int.\n",
    "    return data_file\n",
    "\n",
    "output_frame = get_hourly_exits(input_frame)\n",
    "output_frame.to_csv(\"Output_File.txt\",index=None)#This is our output file containing the deired results which will be used in the next exercise and without wirting index=None an extra column will added displaying the index values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 1.6*\n",
    "\n",
    "Given an entry variable that represents time, in the format:\n",
    "     \"00:00:00\" (hour: minutes: seconds)\n",
    "    \n",
    "Write a function to extract the hour part from the time in the entry variable\n",
    "And return it as an integer. For example:\n",
    "         \n",
    "         1) if hour is 00, your code must return 0\n",
    "         2) if hour is 01, your code must return 1\n",
    "         3) if hour is 21, your code must return 21\n",
    "        \n",
    "Please return te hour as an integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is used to read the data from the input file.\n",
    "import pandas as ps\n",
    "\n",
    "input_frame = ps.read_csv(\"Output_File.txt\")#This is our file created in ealier exercise 1.5 through which we read our data.\n",
    "\n",
    "def time_to_hour(time):\n",
    "    hour = time.TIMEn.str.slice(-8,-6).astype(int)#It is used to extracts the hour part from the TIMEn and converts it to integer.\n",
    "    return hour\n",
    "\n",
    "output_frame = time_to_hour(input_frame)\n",
    "output_frame.to_csv('Output_File.txt',index=None)#This is our output file containing the deired results which will be used in the next exercise and without wirting index=None an extra column will added displaying the index values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Data Analysis\n",
    "\n",
    "### *Exercise 2.1*\n",
    "\n",
    "To understand the relationship between the Subway activity and the weather, please complete the data from the file already downloaded with the weather data.\n",
    "We provided you with the file containing NYC weather data and made it available with the Support Material. You can access it through the link: https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
    "\n",
    "Now that we have our data in a csv file, write Python code that reads this file and saves it into a Pandas Dataframe. \n",
    "\n",
    "Tip: \n",
    "\n",
    "Use the command below to read the file:\n",
    "\n",
    "```python\n",
    "pd.read_csv('output_list.txt', sep=\",\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This module is used to read the data from the input file.\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"turnstile_data_master_with_weather.csv\" #This is the file present in a single folder from which is used to read the data\n",
    "data_file=pd.read_csv(filename,sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.2*\n",
    "\n",
    "Now, create a function that calculates the number of rainy days. For this, return the count of the number of days where the column *\"rain\"* is equal to 1.\n",
    "\n",
    "Tip: You might think that interpreting numbers as integers or floats might not\n",
    "     work at first. To handle this issue, it might be useful to convert\n",
    "     these numbers into integers. You can do this by writting cast (column as integer).\n",
    "     So, for example, if we want to launch the column maxtempi as an integer, we have to\n",
    "     write something like cast (maxtempi as integer) = 76, instead of just\n",
    "     where maxtempi = 76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44104\n"
     ]
    }
   ],
   "source": [
    "#This module is used to read the data from the input file.\n",
    "import pandas as pd \n",
    "\n",
    "filename = \"turnstile_data_master_with_weather.csv\" \n",
    "data_file = pd.read_csv(filename)#This is used to read the data frame from the given file\n",
    "\n",
    "def num_rainy_days(data_file):\n",
    "    \n",
    "    count = data_file['rain'].astype(int).sum()#astype(int) is used to convert the values of column to int datatype and sum is used to calculate the number of rainy days.\n",
    "    return count #this is used to return the resultant value of the function\n",
    "\n",
    "print(num_rainy_days(data_file))#This is used to print the value returned the function above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.3*\n",
    "\n",
    "Calculate if the day was cloudy or not (0 or 1) and the maximum temperature for fog (i.e. the maximum temperature \n",
    "     for cloudy days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.0\n"
     ]
    }
   ],
   "source": [
    "#Module used to read the data from the file.\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"turnstile_data_master_with_weather.csv\" #This is the file from which we read the data frame.\n",
    "data_file=pd.read_csv(filename)\n",
    "\n",
    "def max_temp_aggregate_by_fog(data_file):\n",
    "    \n",
    "    #your code here \n",
    "    data_file = data_file.loc[data_file[\"fog\"]==1]#this is used to filter the data of the file and returns the rows containing value of FOG=1.\n",
    "    max_temp = data_file['maxtempi'].max()#It is used to give the maximum value of the tempi column among the filtered rows.\n",
    "    return max_temp#This is used to return the maximum temperature.\n",
    "\n",
    "print(max_temp_aggregate_by_fog(data_file))#This is used to print the maximum temperature in the foggy days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.4\n",
    "\n",
    "Now, calculate the mean for 'meantempi' for the days that are Saturdays or Sundays (weekend):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.10066685403307\n"
     ]
    }
   ],
   "source": [
    "#Module used to read the data from the file.\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"turnstile_data_master_with_weather.csv\" #This file is used to interpret our results.\n",
    "\n",
    "data_file=pd.read_csv(filename)\n",
    "\n",
    "def avg_weekend_temperature(filename):\n",
    "    filename['DATEn']=pd.to_datetime(filename.DATEn)#Convert the datatype of the column from object to datetime\n",
    "    day=(filename.DATEn.dt.weekday).astype(int)#retrieves the day[0-6] from the given DATE where is 0 is for Monday and 6 is for sunday. while \n",
    "    filename = filename.loc[(day==5) | (day==6)]#It is used to filter the data of the file and gives the rows with day=5(saturday)and day=6(sunday)\n",
    "    mean_temperature_weekends = filename[\"meantempi\"].mean()#It is used to take out the mean of the column 'meantempi' of the filtered data.\n",
    "    return mean_temperature_weekends\n",
    "\n",
    "print(avg_weekend_temperature(data_file))#It is used to print the value returned by the function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.5\n",
    "\n",
    "Calculate the mean of the minimum temperature 'mintempi' for the days when the minimum temperature was greater that 55 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.2699012987013\n"
     ]
    }
   ],
   "source": [
    "#This module is used to read the file.\n",
    "import pandas as pd\n",
    "\n",
    "filename=\"turnstile_data_master_with_weather.csv\"#Using the pandas module we are able to read this file\n",
    "data_file=pd.read_csv(filename)\n",
    "\n",
    "def avg_min_temperature(filename):\n",
    "\n",
    "    filename =filename.loc[filename['mintempi']>55]#This is used to fetch those rows which have value of'mintempi'>55\n",
    "    avg_min_temperature_rainy = filename['mintempi'].mean()#Used to calculate the mean of the filtered data.   \n",
    "    return avg_min_temperature_rainy\n",
    "\n",
    "print(avg_min_temperature(data_file))#This is used to print the value returned by the function above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.6\n",
    "\n",
    "Before you make any analysis, it might be useful to look at the data we want to analyse. More specifically, we will evaluate the entries by hour in our data from the NYC Subway to determine the data distribution. This data is stored in the column ['ENTRIESn_hourly'].\n",
    "    \n",
    "Draw two histogramns in the same axis, to show the entries when it's raining vs when it's not. \n",
    "Below, you will find an example of how to draw histogramns with Pandas and Matplotlib:\n",
    "     \n",
    "```python\n",
    "Turnstile_weather ['column_to_graph']. Hist ()\n",
    "```   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X2cVWW5//HPV0QpRUDMSRl/DhaeBEmBUenY0SlN0Dw+HLGjeRLU5JWK1Ul+afbr+HTq9IAntdMTloodj2iUSSYZqaOZooASiGSMgjGJ4JHHUSnB6/fHumfczNrztJlhnr7v12u/9lrXute97muzmWuvh722IgIzM7NCu3T2AMzMrOtxcTAzsxwXBzMzy3FxMDOzHBcHMzPLcXEwM7McF4deTtJSSVWdPY6uQNKVkn7UzPJJkh7bmWPqynb26yFppaTjd9b2ejsXhx6s2H+mxv+hI2JERFS30E+FpJC0awcNtUuIiK9FxKehfXJOr/+bkuoKHv+Vlk1K/f/fRuvUSqqS9IOCdf4m6a2C+TkF46uPrZR0RZHtH1+wvW2NxlInaf+0/MOSHpe0UdI6Sb+XdESpuVv316P/s1v3IGnXiNja2ePoIP8YEb9tYtk64HJJP4yITYULIuIzwGcAJF0NvD8i/qV+uaSKNDkwIrZKqgQekbQwIuY2sb0nIuLDjYOS9gLuAy4C7gZ2A/4B+GvrUuxYPfz90WV5z6GXa/Tp8khJCyRtkrRG0n+mZo+m5w3p0+aHJO0i6f9JeknSWkm3SxpQ0O+5adlrkr7SaDtXS5ol6b8lbQImpW0/IWmDpNWS/kvSbgX9haSLJS2XtFnSdZLel9bZJOnuwvaNcnxJ0pg0/S+pr+Fp/tOSflEwrv9uKueC/qZJWi9phaQTd+DlXwY8AfzrDvQBQEQsAJYCh5ew+sGpjzsjYltEvBkRv4mIxa1ZuanXQ9L+kmanPZEaSRcWLLtN0r8XzFdJqi2YXynpckmLgdcL9+AkvVfSG5IGF8TGSHpVUt8S8rciXBys0I3AjRGxF/A+sk+RAMek54ERsWdEPAFMSo+PAAcBewL1h0yGA98DzgH2AwYAQxpt61RgFjAQuAPYRvZHch/gQ8BxwMWN1hkPjAHGAl8EpqdtHAAcCpzdRF6PAFUFubwIHFsw/0iRdYrlDHAU8Hwa5zeBH0tSE9ttja8A/ypp7x3oA0ljyV6DmhJW/xOwTdIMSSdKGtSGdZt7Pe4EaoH9gQnA1yQd14a+zwY+Tto7qg9GxCtANfCJgrb/AsyMiLfa0L81w8Wh5/tF+jS+QdIGsj/aTXkLeL+kfSKiLiLmNdP2HOA/I+LFiKgDvgSclT7hTQB+GRGPRcTfgH8DGt/E64mI+EVEvJ0+qS6MiHkRsTUiVgI/5J0/4PW+ERGbImIp8Czwm7T9jcAcYFQTY32koK9/AP6jYP5YiheHprwUETdHxDZgBlnxK2um/Xavf+GnZ4CIWAT8Bri8DWMo9L+S3iTbA/ke8Itm2o5tNJYX0hg2AR8m+ze6GXg1feJvLq96RV8PSQekPi+PiC0pzx8Bn2pDbjdFxKqIeLPIshlkBQFJfcgKyU/a0Le1wMWh5zstIgbWP8h/Gi90Adkhhj9Kmi/p5Gba7g+8VDD/Etk5rLK0bFX9goh4A3it0fqrCmckHSzpPkmvpENNXyP7NFpoTcH0m0Xm92xirI8A/yDpvUAf4C7g6HTcfgCwqIn1inmlfiLlRTPbhUavf0TcXKTNvwEXpfG11T5p+1PJ9o6aO6wyr9FY3le/ICKWRcSkiCgn2wPZH7ihFdtv6vXYH1gXEZsL2r5Efg+yOauaWXYvMFzSQcDHgI0R8VQb+rYWuDhYg4hYHhFnA/sC3wBmSdqD/Kd+gJeBAwvm/w+wlewP9mqgvH6BpHcBg9le4z6/D/wRGJYOa10J7Mjhmnc2FFEDvAF8Fng0/cF6BZgMPBYRbxdbrT223crx/RH4OVnOpay/LSKuB7bQfPFvy3huIysSpXoZ2FtS/4LY/wH+kqZfB95dsKxYYWzy3yAitpAd9jyHbG/Eew3tzMXBGqSTte9Jfyw3pPA24FXgbbJzC/XuJDtWPlTSnmSf9O9Kx4ZnAf8o6e/TSeJraPkPfX9gE1An6QNkV860p0eAKbxzCKm60XxjxXLuSNcA55GdgynV14EvSurXlpUkfUDSZZLK0/wBZIdpmjus2KyIWAU8DvyHpH6SPki2Z3pHarIIOEnS3mmP6fMlbOZ2svNepwD/3XxTaysXBys0HlgqqY7s5PRZ6XjxG8BXgd+nY9VjgVvIPq09Cqwg+9R6KUA6J3ApMJNsL2IzsJbmL42cCnwytb2Z7NBPe3qErAA92sT8dprIuRS/1PbfK7inie2tIHs99yhxOwC/AtYDFzax/EPKf8/hCLLX/CjgSUmvkxWFZ4HLdmAskBWYCrK9iHuAqwous/0J8AdgJdk5lzb/e0fE78kK+NPpPJW1I/nHfqyjpT2LDWSHjFZ09nis55D0EPA/EdHkN9utNN5zsA4h6R8lvTuds5gGLCH7lGjWLtJez2jafy/TcHGwjnMq2eGEl4FhZIeovJvazWj723gUPn7QyeOaAfwW+HyjK6KsnfiwkpmZ5XjPwczMcrrtjff22WefqKioKGnd119/nT322JGLQrqP3pJrb8kTnGtPtLPyXLhw4f9GxHta07bbFoeKigoWLFhQ0rrV1dVUVVW174C6qN6Sa2/JE5xrT7Sz8pT0UsutMj6sZGZmOS4OZmaW4+JgZmY53facg5l1nrfeeova2lq2bNnSodsZMGAAy5Yt69BtdAXtnWe/fv0oLy+nb9/Sf/vIxcHM2qy2tpb+/ftTUVHBjv3WUfM2b95M//79W27YzbVnnhHBa6+9Rm1tLUOHDi25nxYPK0n6O0mLCh6bJH0+3U1xrrKfbZxb/+tRytyUfhZwsaTRBX1NTO2XS5pYEB8jaUla56Yd/GUtM+tgW7ZsYfDgwR1aGKw0khg8ePAO79W1WBwi4vmIODwiDif7icY3yO6weAXwYEQMAx5M8wAnkt0uYRjZ/fK/nwa8N3AV2d0fjwSuKvg5wu+ntvXrjd+hrMysw7kwdF3t8W/T1hPSxwEvRMRLZPfOmZHiM4DT0vSpwO2RmQcMlLQfMA6YGxHrImI9MBcYn5btFRFPpHvv3F7Ql5mZdYK2nnM4i+xHXgDKImI1QESslrRvig9h+5/3q02x5uK1ReI5kiaT7WFQVlZGdXV1G4efqaurK3nd7qa35Npb8oSukeuAAQPYvPmd+93132uvdu1/86ZNAGzbtm277ZRiypQpTJkyhQ984APtMbQG++23H6tXr26Xvtojz8a2bNmyQ++TVheH9Itep5D9kHyzTYvEooR4PhgxHZgOUFlZGaV+o/D6O69n6sKpTS6Pq3rOzQj9DdOepyvkumzZsg49UVzfd2tO1EYEEcEuuxQ/EDJjxoyi8fbQXq9BR5x479evH6NGjSp5/bYcVjqR7BeX6n/UfU06JER6XpvitcABBeuVk922ubl4eZG4mVlRK1eu5JBDDuHiiy9m9OjRrFq1iosuuojKykpGjBjBVVdd1dC2qqqq4VY7e+65J1/+8pc57LDDGDt2LGvWrGHz5s0MHTqUt956C4BNmzZRUVHRMF9vxYoVfOhDH+KII47gK1/5SkO8rq6O4447jtGjRzNy5EjuvfdeAL7yla9w4403NrT78pe/zE033dRhr0l7a0txOJt3DikBzAbqrziaCNxbED83XbU0FtiYDj89AJwgaVA6EX0C8EBatlnS2HSV0rkFfZmZFfX8889z7rnn8swzz3DggQfy1a9+lQULFrB48WIeeeQRFi9enFvn9ddfZ+zYsfzhD3/gmGOO4eabb6Z///5UVVXxq1/9CoCZM2dyxhln5L4j8LnPfY6LLrqI+fPn8973vrch3q9fP+655x6efvppHn74YS677DIiggsuuKBhr+Xtt99m5syZnHPOOR34irSvVhUHSe8GPgb8vCD8deBjkpanZV9P8fuBF4East8CvhggItYB1wHz0+PaFIPsx+R/lNZ5AZhTekpm1hsceOCBjB37zk9733333YwePZpRo0axdOlSnnvuudw6u+22GyeffDIAY8aMYeXKlQB8+tOf5tZbbwXg1ltv5bzzzsut+/vf/56zzz4bgE996lMN8Yjgyiuv5IMf/CDHH388f/nLX1izZg0VFRUMHjyYZ555ht/85jeMGjWKwYMHt1v+Ha1V5xzSj60PbhR7jezqpcZtA7ikiX5uIfth+sbxBcChrRmLmRmw3S2uV6xYwbRp05g/fz6DBg1i0qRJRa/z79u3b8Nlnn369GHr1q0AHH300axcuZJHHnmEbdu2ceihxf8cFbtE9I477uDVV19l4cKF9O3bl4qKioZtf/rTn+a2227jlVde4fzzz9/hnHcm31vJzLq9TZs2scceezBgwADWrFnDnDltP/hw7rnncvbZZxfda4CsgMycORPICkK9jRs3su+++9K3b18efvhhXnrpnbtin3766fz6179m/vz5jBs3rs1j6kwuDma24yLa99FGhx12GKNGjWLEiBGcf/75HH300W3u45xzzmH9+vUNh44au/HGG/nud7/LEUccwcaNG7dbb8GCBVRWVnLHHXdsd8nsbrvtxkc+8hE+8YlP0KdPnzaPqTP53kpm1u1UVFTw7LPPbhe77bbbirYtvNa/rq6uYXrChAlMmDChYf6xxx5jwoQJDBw4sGg/Q4cO5YknnmiYv+KK7KYQ++yzz3bxQm+//Tbz5s3jpz/9abP5dEUuDmbW61166aXMmTOH+++/v936fO655zj55JM5/fTTGTZsWLv1u7O4OJhZr/ed73yn3fscPnw4L774Yrv3u7P4nIOZmeW4OJiZWY6Lg5mZ5bg4mJlZjk9Im9kO0zXt+8M/3eHOyLNnz+a5555ruKS1vUyaNImTTz55u8tsO4OLg5lZE7Zu3cquuxb/M3nKKadwyimn7OQR7Tw+rGRm3U79LbsvvPBCRowYwQknnMCbb74JwKJFixg7diwf/OAHOf3001m/fj2Q3br78ssv58gjj+Tggw/md7/7XdG+q6qquPLKKzn22GO58cYb+eUvf8lRRx3FqFGjOP7441mzJvvVgttuu40pU6YA2af9z372s/z93/89Bx10ELNmzQKyG/TV38Ibsm9Tz549e7vtRQSXXXYZw4cP5+Mf/zhr165tWHbttddyxBFHcOihhzJ58mQighdeeIHRo0c3tFm+fDljxozZ0Zc0x8XBzLql5cuXc8kll7B06VIGDhzIz372MyC7R9I3vvENFi9ezMiRI7nmmmsa1tm6dStPPfUUN9xww3bxxjZs2MAjjzzCZZddxoc//GHmzZvHM888w1lnncU3v/nNouusXr2axx57jPvuu6/hUFPh3V43btzI448/zkknnbTdevfccw81NTUsWbKEm2++mccff7xh2ZQpU5g/fz7PPvssb775Jvfddx/ve9/7GDBgAIsWLQKyu8hOmjSp7S9gC1wczKxbGjp0KIcffjjwzu23N27cyIYNGzj22GMBmDhxIo8++mjDOv/0T/+0Xfum/PM//3PDdG1tLePGjWPkyJF861vfYunSpUXXOe2009hll10YPnx4w97FscceS01NDWvXruXOO+/kjDPOyB2mevTRR5kwYQJ9+vRh//3356Mf/WjDsocffpijjjqKkSNH8tBDDzVsu77obNu2jbvuuotPfvKTrX3ZWs3Fwcy6pd13371huvD2261Zp7D9eeedx+GHH77dJ/rC24FfeumlTJkyhSVLlvDDH/6w6K3AG48nCm4e+KlPfYo77rijyd+JgOK3At+yZQsXX3wxs2bNYsmSJVx44YUN2z7jjDOYM2cO9913H2PGjOmQ34lwcTCzHmPAgAEMGjSo4XzCT37yk4a9iKbceuutLFq0qMn7Km3cuJEhQ4YApf0e9aRJk7jhhhsAGDFiRG75Mcccw6xZs9i2bRurV6/m4YcfBmgoBPvssw91dXUN5zEg+/W5cePGcdFFFzVZcHaUr1Yysx3WlS49nTFjBp/5zGd44403OOiggxqO+Zfq6quv5swzz2TIkCGMHTuWFStWtGn9srIyDjnkEE477bSiy+t/82HkyJEcfPDBDcVs4MCBXHjhhYwcOZKKigqOOOKI7dY755xz+PnPf84JJ5xQWmItUJRw7/SuoLKyMup/NLytrr/zeqb+aWqTy7vSG31HVVdXU1VV1dnD6HC9JU/oGrkuW7aMQw45pMO3s3nzZvr379/h2+lIb7zxBiNHjuTpp59mwIABRduUkue0adPYuHEj1113XdHlxf6NJC2MiMrW9O89BzOzDvLb3/6W888/ny984QtNFoZSnH766bzwwgs89NBD7dZnYy4OZmYd5Pjjj+fPf/5zu/d7zz33tHufjfmEtJmVpLseku4N2uPfplXFQdJASbMk/VHSMkkfkrS3pLmSlqfnQamtJN0kqUbSYkmjC/qZmNovlzSxID5G0pK0zk0qdl2XmXUZ/fr147XXXnOB6IIigtdee41+/frtUD+tPax0I/DriJggaTfg3cCVwIMR8XVJVwBXAJcDJwLD0uMo4PvAUZL2Bq4CKoEAFkqaHRHrU5vJwDzgfmA8MGeHMjOzDlNeXk5tbS2vvvpqh25ny5YtO/xHrjto7zz79etHeXn5DvXRYnGQtBdwDDAJICL+BvxN0qlAVWo2A6gmKw6nArdH9pFiXtrr2C+1nRsR61K/c4HxkqqBvSLiiRS/HTgNFwezLqtv374MHTq0w7dTXV3NqFGjOnw7na0r5tmaPYeDgFeBWyUdBiwEPgeURcRqgIhYLWnf1H4IsKpg/doUay5eWySeI2ky2R4GZWVlVFdXt2L4eeW7lzPt4GlNLi+1366orq6uR+XTlN6SJzjXnqgr5tma4rArMBq4NCKelHQj2SGkphQ7XxAlxPPBiOnAdMi+51Dqtd4tfs/h7J5zHLUrXBO/M/SWPMG59kRdMc/WnJCuBWoj4sk0P4usWKxJh4tIz2sL2h9QsH458HIL8fIicTMz6yQtFoeIeAVYJenvUug44DlgNlB/xdFEoP6m5bOBc9NVS2OBjenw0wPACZIGpSubTgAeSMs2SxqbrlI6t6AvMzPrBK29WulS4I50pdKLwHlkheVuSRcAfwbOTG3vB04CaoA3UlsiYp2k64D5qd219SengYuA24B3kZ2I9sloM7NO1KriEBGLyC5Bbey4Im0DuKSJfm4BbikSXwAc2pqxmJlZx/M3pM3MLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLMfFwczMclpVHCStlLRE0iJJC1Jsb0lzJS1Pz4NSXJJuklQjabGk0QX9TEztl0uaWBAfk/qvSeuqvRM1M7PWa8uew0ci4vCIqEzzVwAPRsQw4ME0D3AiMCw9JgPfh6yYAFcBRwFHAlfVF5TUZnLBeuNLzsjMzHbYjhxWOhWYkaZnAKcVxG+PzDxgoKT9gHHA3IhYFxHrgbnA+LRsr4h4IiICuL2gLzMz6wStLQ4B/EbSQkmTU6wsIlYDpOd9U3wIsKpg3doUay5eWyRuZmadZNdWtjs6Il6WtC8wV9Ifm2lb7HxBlBDPd5wVpskAZWVlVFdXNzvoppTvXs60g6c1ubzUfruiurq6HpVPU3pLnuBce6KumGerikNEvJye10q6h+ycwRpJ+0XE6nRoaG1qXgscULB6OfByilc1ileneHmR9sXGMR2YDlBZWRlVVVXFmrXo+juvZ+qfpja5PM4uWpu6perqakp9nbqT3pInONeeqCvm2eJhJUl7SOpfPw2cADwLzAbqrziaCNybpmcD56arlsYCG9NhpweAEyQNSieiTwAeSMs2SxqbrlI6t6AvMzPrBK3ZcygD7klXl+4K/E9E/FrSfOBuSRcAfwbOTO3vB04CaoA3gPMAImKdpOuA+andtRGxLk1fBNwGvAuYkx5mZtZJWiwOEfEicFiR+GvAcUXiAVzSRF+3ALcUiS8ADm3FeM3MbCfwN6TNzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLKfVxUFSH0nPSLovzQ+V9KSk5ZLukrRbiu+e5mvS8oqCPr6U4s9LGlcQH59iNZKuaL/0zMysFG3Zc/gcsKxg/hvAtyNiGLAeuCDFLwDWR8T7gW+ndkgaDpwFjADGA99LBacP8F3gRGA4cHZqa2ZmnaRVxUFSOfBx4EdpXsBHgVmpyQzgtDR9aponLT8utT8VmBkRf42IFUANcGR61ETEixHxN2BmamtmZp1k11a2uwH4ItA/zQ8GNkTE1jRfCwxJ00OAVQARsVXSxtR+CDCvoM/CdVY1ih9VbBCSJgOTAcrKyqiurm7l8LdXvns50w6e1uTyUvvtiurq6npUPk3pLXmCc+2JumKeLRYHSScDayNioaSq+nCRptHCsqbixfZeokiMiJgOTAeorKyMqqqqYs1adP2d1zP1T1ObXB5nF918t1RdXU2pr1N30lvyBOfaE3XFPFuz53A0cIqkk4B+wF5kexIDJe2a9h7KgZdT+1rgAKBW0q7AAGBdQbxe4TpNxc3MrBO0eM4hIr4UEeURUUF2QvmhiDgHeBiYkJpNBO5N07PTPGn5QxERKX5WupppKDAMeAqYDwxLVz/tlrYxu12yMzOzkrT2nEMxlwMzJf078Azw4xT/MfATSTVkewxnAUTEUkl3A88BW4FLImIbgKQpwANAH+CWiFi6A+MyM7Md1KbiEBHVQHWafpHsSqPGbbYAZzax/leBrxaJ3w/c35axmJlZx/E3pM3MLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxaEYKXuYmfVSLg5mZpbj4mBmZjkuDmZmluPiYGZmOS4OZmaW4+JgZmY5Lg5mZpbj4mBmZjkuDmZmluPiYGZmOS4OZmaW4+JgZmY5Lg5mZpbj4mBmZjkuDmZmltNicZDUT9JTkv4gaamka1J8qKQnJS2XdJek3VJ89zRfk5ZXFPT1pRR/XtK4gvj4FKuRdEX7p2lmZm3Rmj2HvwIfjYjDgMOB8ZLGAt8Avh0Rw4D1wAWp/QXA+oh4P/Dt1A5Jw4GzgBHAeOB7kvpI6gN8FzgRGA6cndqamVknabE4RKYuzfZNjwA+CsxK8RnAaWn61DRPWn6cJKX4zIj4a0SsAGqAI9OjJiJejIi/ATNTWzMz6yS7tqZR+nS/EHg/2af8F4ANEbE1NakFhqTpIcAqgIjYKmkjMDjF5xV0W7jOqkbxo5oYx2RgMkBZWRnV1dWtGX5O+e7lTDt4WpPLq+sXldh/V1JXV1fy69Sd9JY8wbn2RF0xz1YVh4jYBhwuaSBwD3BIsWbpudiPL0cz8WJ7L1EkRkRMB6YDVFZWRlVVVfMDb8L1d17P1D9NbXJ5XN2wwZL670qqq6sp9XXqTnpLnuBce6KumGebrlaKiA1ANTAWGCipvriUAy+n6VrgAIC0fACwrjDeaJ2m4mZm1klac7XSe9IeA5LeBRwPLAMeBiakZhOBe9P07DRPWv5QRESKn5WuZhoKDAOeAuYDw9LVT7uRnbSe3R7JmZlZaVpzWGk/YEY677ALcHdE3CfpOWCmpH8HngF+nNr/GPiJpBqyPYazACJiqaS7geeArcAl6XAVkqYADwB9gFsiYmm7ZWhmZm3WYnGIiMXAqCLxF8muNGoc3wKc2URfXwW+WiR+P3B/K8ZrZmY7gb8hbWZmOS4OZmaW4+JgZmY5Lg5mZpbj4mBmZjkuDmZmluPiYGZmOS4OZmaW4+JgZmY5Lg5mZpbj4mBmZjkuDmZmluPiYGZmOS4OZmaW4+JgZmY5Lg5mZpbj4mBmZjkuDmZmluPiYGZmOS4OZmaW02JxkHSApIclLZO0VNLnUnxvSXMlLU/Pg1Jckm6SVCNpsaTRBX1NTO2XS5pYEB8jaUla5yZJ6ohkzcysdVqz57AVuCwiDgHGApdIGg5cATwYEcOAB9M8wInAsPSYDHwfsmICXAUcBRwJXFVfUFKbyQXrjd/x1MzMrFQtFoeIWB0RT6fpzcAyYAhwKjAjNZsBnJamTwVuj8w8YKCk/YBxwNyIWBcR64G5wPi0bK+IeCIiAri9oC8zM+sEbTrnIKkCGAU8CZRFxGrICgiwb2o2BFhVsFptijUXry0SNzOzTrJraxtK2hP4GfD5iNjUzGmBYguihHixMUwmO/xEWVkZ1dXVLYy6uPLdy5l28LQml1fXLyqx/66krq6u5NepO+kteYJz7Ym6Yp6tKg6S+pIVhjsi4ucpvEbSfhGxOh0aWpvitcABBauXAy+neFWjeHWKlxdpnxMR04HpAJWVlVFVVVWsWYuuv/N6pv5papPL4+qGDZbUf1dSXV1Nqa9Td9Jb8gTn2hN1xTxbc7WSgB8DyyLiPwsWzQbqrziaCNxbED83XbU0FtiYDjs9AJwgaVA6EX0C8EBatlnS2LStcwv6MjOzTtCaPYejgU8BSyQtSrErga8Dd0u6APgzcGZadj9wElADvAGcBxAR6yRdB8xP7a6NiHVp+iLgNuBdwJz0MDOzTtJicYiIxyh+XgDguCLtA7ikib5uAW4pEl8AHNrSWMzMbOfwN6TNzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLMfFwczMclwczMwsx8XBzMxyXBzMzCzHxcHMzHJcHMzMLKfF4iDpFklrJT1bENtb0lxJy9PzoBSXpJsk1UhaLGl0wToTU/vlkiYWxMdIWpLWuUmS2jtJMzNrm9bsOdwGjG8UuwJ4MCKGAQ+meYD6REDLAAAHbElEQVQTgWHpMRn4PmTFBLgKOAo4EriqvqCkNpML1mu8LTMz28laLA4R8SiwrlH4VGBGmp4BnFYQvz0y84CBkvYDxgFzI2JdRKwH5gLj07K9IuKJiAjg9oK+zMysk+xa4nplEbEaICJWS9o3xYcAqwra1aZYc/HaIvGiJE0m28ugrKyM6urqkgZfvns50w6e1uTy6vpFJfbfldTV1ZX8OnUnvSVPcK49UVfMs9Ti0JRi5wuihHhRETEdmA5QWVkZVVVVJQwRrr/zeqb+aWqTy+Pqhg2W1H9XUl1dTamvU3fSW/IE59oTdcU8S71aaU06JER6XpvitcABBe3KgZdbiJcXiZuZWScqdc9hNjAR+Hp6vrcgPkXSTLKTzxvTYacHgK8VnIQ+AfhSRKyTtFnSWOBJ4FzgOyWOqd3o6jRxTdMXTsVV3X+vwsysKS0WB0l3AlXAPpJqya46+jpwt6QLgD8DZ6bm9wMnATXAG8B5AKkIXAfMT+2ujYj6k9wXkV0R9S5gTnqYmVknarE4RMTZTSw6rkjbAC5pop9bgFuKxBcAh7Y0DjMz23n8DWkzM8txcTAzsxwXBzMzy3FxMDOzHBcHMzPLcXEwM7McFwczM8txcTAzsxwXBzMzy3FxMDOzHBcHMzPLcXEwM7Oc9v6xn15DzdzOG3xLbzPr3rznYGZmOS4OZmaW4+JgZmY5Lg5mZpbj4mBmZjkuDmZmluNLWTtIS5e6gi93NbOuy3sOZmaW02X2HCSNB24E+gA/ioivd/KQOpy/SGdmXVWXKA6S+gDfBT4G1ALzJc2OiOc6d2Sdy4emzKyzdIniABwJ1ETEiwCSZgKnAr26OLRGSwVk2sHT+Mg1H+nQMbhAmfU8XaU4DAFWFczXAkc1biRpMjA5zdZJer7E7e0D/G+J63YrU5na4bnq6pb3cHaCXvNvinPtiXZWnge2tmFXKQ7F/rrkPo5GxHRg+g5vTFoQEZU72k930Fty7S15gnPtibpinl3laqVa4ICC+XLg5U4ai5lZr9dVisN8YJikoZJ2A84CZnfymMzMeq0ucVgpIrZKmgI8QHYp6y0RsbQDN7nDh6a6kd6Sa2/JE5xrT9Tl8lSErzQxM7PtdZXDSmZm1oW4OJiZWU6vKg6Sxkt6XlKNpCs6ezytJekWSWslPVsQ21vSXEnL0/OgFJekm1KOiyWNLlhnYmq/XNLEgvgYSUvSOjdJ6pQvLkg6QNLDkpZJWirpcyneE3PtJ+kpSX9IuV6T4kMlPZnGfVe6QANJu6f5mrS8oqCvL6X485LGFcS7zPtdUh9Jz0i6L8331DxXpvfXIkkLUqx7vn8jolc8yE50vwAcBOwG/AEY3tnjauXYjwFGA88WxL4JXJGmrwC+kaZPAuaQfXdkLPBkiu8NvJieB6XpQWnZU8CH0jpzgBM7Kc/9gNFpuj/wJ2B4D81VwJ5pui/wZMrhbuCsFP8BcFGavhj4QZo+C7grTQ9P7+XdgaHpPd6nq73fgS8A/wPcl+Z7ap4rgX0axbrl+7c37Tk03KIjIv4G1N+io8uLiEeBdY3CpwIz0vQM4LSC+O2RmQcMlLQfMA6YGxHrImI9MBcYn5btFRFPRPbuu72gr50qIlZHxNNpejOwjOzb8z0x14iIujTbNz0C+CgwK8Ub51r/GswCjkufGk8FZkbEXyNiBVBD9l7vMu93SeXAx4EfpXnRA/NsRrd8//am4lDsFh1DOmks7aEsIlZD9kcV2DfFm8qzuXhtkXinSocTRpF9ou6RuaZDLYuAtWR/AF4ANkTE1iLja8gpLd8IDKbtr0FnuAH4IvB2mh9Mz8wTsgL/G0kLld3uB7rp+7dLfM9hJ2nVLTp6gKbybGu800jaE/gZ8PmI2NTMYdVunWtEbAMOlzQQuAc4pFiz9NzWnIp98NvpuUo6GVgbEQslVdWHizTt1nkWODoiXpa0LzBX0h+badul37+9ac+hp92iY03azSQ9r03xpvJsLl5eJN4pJPUlKwx3RMTPU7hH5lovIjYA1WTHnQdKqv/QVji+hpzS8gFkhxrb+hrsbEcDp0haSXbI56NkexI9LU8AIuLl9LyWrOAfSXd9/3bWiZud/SDbS3qR7GRW/YmrEZ09rjaMv4LtT0h/i+1Pcn0zTX+c7U9yPZXiewMryE5wDUrTe6dl81Pb+pNcJ3VSjiI7jnpDo3hPzPU9wMA0/S7gd8DJwE/Z/kTtxWn6ErY/UXt3mh7B9idqXyQ7Sdvl3u9AFe+ckO5xeQJ7AP0Lph8HxnfX92+nvVE66R/vJLIrYF4AvtzZ42nDuO8EVgNvkX16uIDsOOyDwPL0XP/mEdkPJ70ALAEqC/o5n+xEXg1wXkG8Eng2rfNfpG/Od0KeHybbTV4MLEqPk3porh8Enkm5Pgv8W4ofRHZFSk36A7p7ivdL8zVp+UEFfX055fM8BVevdLX3O9sXhx6XZ8rpD+mxtH4s3fX969tnmJlZTm8652BmZq3k4mBmZjkuDmZmluPiYGZmOS4OZmaW4+JgZmY5Lg5mZpbz/wHSLm7VNxe45QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#These are the necessary modules needed\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filename=\"turnstile_data_master_with_weather.csv\"#This file is read using the pandas module\n",
    "data_file=pd.read_csv(filename)\n",
    "\n",
    "def entries_histogram(turnstile_weather):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Histogram with ENTRIES_hourly\")#This is used to display the title of our plotted histogram\n",
    "    turnstile_weather.loc[turnstile_weather['rain']==1]['ENTRIESn_hourly'].hist(histtype='bar',bins=30,color='red',rwidth= 2.5,label='rainy day')#This code is used to display the histogram with hourly entries when it is raining\n",
    "    turnstile_weather.loc[turnstile_weather['rain']==0]['ENTRIESn_hourly'].hist(histtype='bar',bins=30,color='green',rwidth=2.5,label='non-rainy day')#This code is used to display the histogram with hourly entries when it is not raining\n",
    "    plt.legend()#This helps us to use legends in our histogram to make it more informative.\n",
    "    return plt\n",
    "\n",
    "entries_histogram(data_file).show()#This is used to call the above function which is used to plot a histogram with hourly entries for rainy and non rainy day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.7\n",
    "\n",
    "The data you just plotted is in what kind of distribution? Is there a difference in distribution between rainy and non-rainy days?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer **: The data plotted or shown in the above histogram is in the skewed distribution form.It is more of an Asymmetrical dataset and is a Right skewed distribution. Yes, we can see a difference in the distribution between the rainy and the non-rainy days as the hourly entries on rainy day is less than that of non-rainy day.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 2.8\n",
    "\n",
    "Build a function that returns:\n",
    "\n",
    "1. The mean of entries when it's raining\n",
    "2. The mean of entries when it's not raining\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105.4463767458733, 1090.278780151855, ' ')\n"
     ]
    }
   ],
   "source": [
    "#These are necessary modules needed\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filename=\"turnstile_data_master_with_weather.csv\" #We read this file using the pandas module. \n",
    "data_file=pd.read_csv(filename)\n",
    "\n",
    "def means(turnstile_weather):\n",
    "    \n",
    "    p=\" \" #Just took it as an empty string.\n",
    "    ### YOUR CODE HERE ###\n",
    "    rainy_day=turnstile_weather.loc[turnstile_weather['rain']==1]#This is used to filter the data and gives the data only of rainy days\n",
    "    non_rainy_day=turnstile_weather.loc[turnstile_weather['rain']==0]#This is used to filter the data and gives that of non-rainy day\n",
    "    with_rain_mean = rainy_day['ENTRIESn_hourly'].mean()#This is used to take out the mean of the rainy day datasets.\n",
    "    without_rain_mean = non_rainy_day['ENTRIESn_hourly'].mean()#This is used to take out the mean of the non-rainy day datasets.\n",
    "    \n",
    "    return with_rain_mean, without_rain_mean, p # leave this line for the grader\n",
    "\n",
    "print(means(data_file))#This is used to call the above function and print the values retuened by the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to the following questions according to your functions' exits:\n",
    "\n",
    "1. What is the mean of entries when it's raining?\n",
    "2. What is the mean of entries when it's not raining?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer **: Mean of the entries when it is raining: 1105.4463767458733, \n",
    "              Mean of the entries when it is not raining: 1090.278780151855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Map Reduce\n",
    "\n",
    "### *Exercise 3.1*\n",
    "\n",
    "The entry for this exercise is the same file from the previous session (Exercise 2). You can download the file from this link:\n",
    "\n",
    " https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
    "\n",
    "Now, we will create a mapper. For each entry line, the mapper exit must PRINT (not return) UNIT as a key, and the number of ENTRIESn_hourly as the value. Separate the key and the value with a tab. For example: 'R002 \\ t105105.0'\n",
    "\n",
    "Export your mapper into a file named mapper_result.txt and send it with your submission. The code for exporting your mapper is already written in the code bellow.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the necessary module needed for this exercise.\n",
    "import sys\n",
    "\n",
    "sys.stdin = open('turnstile_data_master_with_weather.csv')#Using the module are able to read the given file.\n",
    "sys.stdout = open('mapper_result.txt', 'w')#Using the module we are able to able to create the file named 'mapper_result.txt' which contains the results.\n",
    "\n",
    "def mapper():\n",
    "    sys.stdin.readline() #This is used to read the first line of the file and skip it inorder to prevent undsired results.\n",
    "    for line in sys.stdin:\n",
    "        data = line.strip().split(',')\n",
    "        if len(data)==22: #This condition will work only when it finds a row with 22 columns and evrything else will be ignored.\n",
    "            print(\"{0}\\t{1}\".format(data[1],data[6])) #In this data[1] is UNIT column and data[6] is the ENTRIESn_hourly column and will print them in 'mapper.txt' with '\\t' in between.\n",
    "                  \n",
    "mapper() #This is used to call the function created above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercise 3.2*\n",
    "\n",
    "Now, create the reducer. Given the mapper result from the previous exercise, the reducer must print (not return) one line per UNIT, with the total number of ENTRIESn_hourly during May (which is our data duration), separated by a tab. An example of exit line from the reducer may look like this: 'R001 \\ t500625.0'\n",
    "\n",
    "You can assume that the entry for the reducer is ordered in a way that all lines corresponding to a particular unit are grouped. However, the reducer exit will have repetition, as there are stores that appear in different files' locations.\n",
    "\n",
    "Export your reducer into a file named reducer_result.txt and send it with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.stdin = open('mapper_result.txt','r')#This is used to read the file mapper.txt which is in one folder where this is as well.\n",
    "sys.stdout = open('reducer_result.txt', 'w')#This is used to produce the results in a file named 'reducer_result.txt'\n",
    "\n",
    "def reducer():\n",
    "    \n",
    "    sum = 0\n",
    "    old_key = None\n",
    "    for line in sys.stdin:\n",
    "        # your code here\n",
    "        mapped_data = line.strip().split('\\t')\n",
    "        if len(mapped_data)!= 2:#if result from mapper has two or more columns then skip it.\n",
    "            continue\n",
    "        new_key, val = mapped_data#else if the columns are equal to two then set UNITS=key and ENTRIESN_hourly as value.\n",
    "        \n",
    "        if old_key != new_key:#printing the UNIT and total ENTRIESN_hourly once as long as old_key!= new_Key and as it finds the new key we print result of the old_key.\n",
    "            print(old_key, \"\\t\", sum)\n",
    "            old_key = new_key\n",
    "            sum = 0 #Here we set the value of the variable sum = 0 for next UNIT that is when new key is found. \n",
    "        old_key = new_key \n",
    "        sum += float(val)#we will keep adding the sum to the previous sum as long as the old_key and new_key are same\n",
    "        \n",
    "    if old_key != None: #This is used to print the last UNIT.\n",
    "        print(old_key,\"\\t\",sum)\n",
    "        \n",
    "reducer() #This is used to call the function created above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
